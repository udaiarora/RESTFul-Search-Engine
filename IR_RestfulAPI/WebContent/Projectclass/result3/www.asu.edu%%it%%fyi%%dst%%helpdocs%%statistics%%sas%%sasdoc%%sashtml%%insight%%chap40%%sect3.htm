<HTML>
<HEAD>
<TITLE>Principal Component Analysis</TITLE>
<LINK REL="STYLESHEET" TYPE="text/css" HREF="../sas.css">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<!--Navigation Panel-->
<TABLE BORDER="0" CELLPADDING="0">
<TR VALIGN="TOP">
  <TD ALIGN="CENTER">
  <A NAME="topofpage" HREF="index.htm">
  <IMG BORDER="0" SRC="../../common/images/cont1.gif" ALT="Chapter Contents" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Chapter Contents</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect2.htm"><IMG BORDER="0" SRC="../../common/images/prev1.gif" ALT="Previous" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Previous</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect4.htm"><IMG BORDER="0" SRC="../../common/images/next1.gif" ALT="Next" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Next</FONT></A></TD>
</TR>
</TABLE>
<TABLE BGCOLOR="#CCCC99" WIDTH="100%" CELLPADDING=4>
<TR>
  <TD VALIGN=MIDDLE CLASS="chaphead"><I><FONT SIZE="2">Multivariate Analyses</FONT></I></TD>
</TR>
</TABLE><BR>
<P><!--End of Navigation Panel-->
<H2>Principal Component Analysis  </H2>
<A NAME="idxmult0034">&#13;</A><A NAME="idxmult0033">&#13;</A><A NAME="idxmult0036">&#13;</A><A NAME="idxmult0035">&#13;</A><A NAME="idxmult0037">&#13;</A>Principal component analysis was originated by Pearson (1901)
and later developed by Hotelling (1933).
It is a multivariate technique
for examining relationships among several quantitative variables.
Principal component analysis can be used to summarize data and
detect linear relationships.
It can also be used for exploring
polynomial relationships and for multivariate outlier detection
(Gnanadesikan 1997).
<P>Principal component analysis reduces the dimensionality
of a set of data while trying to preserve the structure.
Given a data set with <SPAN CLASS="mathfont"> <I>n</I><SUB><I>y</I></SUB></SPAN> <SPAN CLASS="ssbeleven"><B>Y</B></SPAN> variables,
<SPAN CLASS="mathfont"> <I>n</I><SUB><I>y</I></SUB></SPAN> eigenvalues and their associated eigenvectors
can be computed from its covariance or correlation matrix.
The eigenvectors are standardized to unit length.
<A NAME="idxmult0038">&#13;</A><A NAME="idxmult0039">&#13;</A>The principal components are linear
combinations of the <SPAN CLASS="ssbeleven"><B>Y</B></SPAN> variables.
The coefficients of the linear combinations are the
eigenvectors of the covariance or correlation matrix.
Principal components are formed as follows:
<UL>
<LI> The first principal component is the linear combination of the
<SPAN CLASS="ssbeleven"><B>Y</B></SPAN> variables that accounts for the greatest
 possible variance.
<LI> Each subsequent principal component is the linear combination
of the <SPAN CLASS="ssbeleven"><B>Y</B></SPAN> variables that has the greatest
possible variance
and is uncorrelated with the previously defined components.
</UL>
<P>For a covariance or correlation matrix, the sum of
its eigenvalues equals the <I>trace</I> of the matrix,
that is, the sum of the variances of the <SPAN CLASS="mathfont"> <I>n</I><SUB><I>y</I></SUB></SPAN>
variables for a covariance matrix, and <SPAN CLASS="mathfont"> <I>n</I><SUB><I>y</I></SUB></SPAN>
for a correlation matrix.
The principal components are sorted by descending order of
their variances, which are equal to the associated eigenvalues.
<A NAME="idxmult0040">&#13;</A><BR>
<P>Principal components can be used to reduce the number of variables in
statistical analyses.
Different methods for selecting the number of
principal components to retain have been suggested.
One simple criterion is to retain components with associated
eigenvalues greater than the average eigenvalue (Kaiser 1958).
SAS/INSIGHT software offers this criterion as an option
for selecting the numbers of eigenvalues, eigenvectors,
and principal components in the analysis.
<A NAME="idxmult0041">&#13;</A>Principal components have a variety of useful properties
(Rao 1964; Kshirsagar 1972):
<P><UL>
<LI> The eigenvectors are orthogonal, so the principal
components represent jointly perpendicular directions
through the space of the original variables.
<LI> The principal component scores are jointly uncorrelated.
Note that this property is quite distinct from the previous one.
<LI> The first principal component has the largest variance of
any unit-length linear combination of the observed
variables. The <SPAN CLASS="mathfont"><I>j</I></SPAN>th principal component has the largest
variance of any unit-length linear combination orthogonal to
the first <SPAN CLASS="mathfont"><I>j</I>-1</SPAN> principal components. The last principal
component has the smallest variance of any linear
combination of the original variables.
<LI> The scores on the first <SPAN CLASS="mathfont"><I>j</I></SPAN> principal components have the
highest possible generalized variance of any set of
unit-length linear combinations of the original variables.
<LI> In geometric terms, the <SPAN CLASS="mathfont"><I>j</I></SPAN>-dimensional linear subspace
spanned by the first <SPAN CLASS="mathfont"><I>j</I></SPAN> principal components gives the best
possible fit to the data points as measured by the sum of
squared perpendicular distances from each data point to the
subspace. This is in contrast to the geometric interpretation of
least squares regression, which minimizes the sum of squared vertical
distances.  For example, suppose you have two variables.  Then,
the first principal component minimizes the sum of squared
perpendicular distances from the points to the first principal axis.
This is in contrast to least squares, which would minimize the sum of
squared vertical distances from the points to the fitted line.
<P></UL>
<P>SAS/INSIGHT software computes principal components from either
the correlation or the covariance matrix.  The covariance matrix
can be used when the variables are measured on comparable scales.
Otherwise, the correlation matrix should be used.
The new variables with principal component scores have variances
equal to corresponding eigenvalues (<SPAN CLASS="ssbeleven"><B>Variance=Eigenvalues</B></SPAN>)
or one (<SPAN CLASS="ssbeleven"><B>Variance=1</B></SPAN>).
You specify the computation method and type of output components
in the method options dialog, as shown in <A HREF="sect2.htm#multivariatemathodoptionsdialog">Figure 40.3</A>.
By default, SAS/INSIGHT software uses the correlation matrix
with new variable variances equal to corresponding eigenvalues.
<P>
<P>
<!--Navigation Panel-->
<TABLE BORDER="0" CELLPADDING="0">
<TR VALIGN="TOP">
  <TD ALIGN="CENTER">
  <A HREF="index.htm">
  <IMG BORDER="0" SRC="../../common/images/cont1.gif" ALT="Chapter Contents" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Chapter Contents</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect2.htm"><IMG BORDER="0" SRC="../../common/images/prev1.gif" ALT="Previous" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Previous</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect4.htm"><IMG BORDER="0" SRC="../../common/images/next1.gif" ALT="Next" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Next</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="#topofpage">
  <IMG BORDER="0" SRC="../../common/images/top1.gif" ALT="Top" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Top</FONT></A></TD>
</TR>
</TABLE>
<P><!--End of Navigation Panel-->
<P><FONT SIZE="1"><A HREF="../../common/images/copyrite.htm">Copyright &copy; 1999 by SAS Institute Inc., Cary, NC, USA. All rights reserved.</A></FONT>
</BODY>
</HTML>
