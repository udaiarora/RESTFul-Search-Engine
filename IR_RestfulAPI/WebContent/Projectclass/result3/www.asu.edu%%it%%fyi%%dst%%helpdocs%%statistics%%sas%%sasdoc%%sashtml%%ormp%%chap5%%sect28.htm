<HTML>
<HEAD>
<TITLE>Finite-Difference Approximations of Derivatives</TITLE>
<LINK REL="STYLESHEET" TYPE="text/css" HREF="../sas.css">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<A NAME="nlpfdad">&#13;</A>
<!--Navigation Panel-->
<TABLE BORDER="0" CELLPADDING="0">
<TR VALIGN="TOP">
  <TD ALIGN="CENTER">
  <A NAME="topofpage" HREF="index.htm">
  <IMG BORDER="0" SRC="../../common/images/cont1.gif" ALT="Chapter Contents" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Chapter Contents</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect27.htm"><IMG BORDER="0" SRC="../../common/images/prev1.gif" ALT="Previous" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Previous</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect29.htm"><IMG BORDER="0" SRC="../../common/images/next1.gif" ALT="Next" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Next</FONT></A></TD>
</TR>
</TABLE>
<TABLE BGCOLOR="#CCCC99" WIDTH="100%" CELLPADDING=4>
<TR>
  <TD VALIGN=MIDDLE CLASS="chaphead"><I><FONT SIZE="2">The NLP Procedure</FONT></I></TD>
</TR>
</TABLE><BR>
<P><!--End of Navigation Panel-->
<H2>Finite-Difference Approximations of Derivatives</H2>
<P><A NAME="idxnlp0459">&#13;</A>The FD= and FDHESSIAN= options specify the use of finite
difference approximations of the derivatives.
The FD= option specifies that all derivatives are approximated
using function evaluations, and
the FDHESSIAN= option specifies that
second-order derivatives are approximated using gradient evalutions.
<P>Computing derivatives by finite-difference approximations can be
very time consuming, especially for second-order derivatives
based only on values of the objective function (FD= option).
If analytical derivatives are difficult to obtain (for example, if
a function is computed by an iterative process),
you might consider one of the optimization techniques that
uses first-order derivatives only (TECH=QUANEW, TECH=DBLDOG, or
TECH=CONGRA).
<P><H4><I>Forward Difference Approximations</I></H4>
<P>The forward-difference derivative approximations consume less
computer time but are usually not as precise as those using
central-difference formulas.
<P><UL>
<LI> First-order derivatives: <SPAN CLASS="mathfont"><I>n</I></SPAN> additional function
      calls are needed:

<DL CLASS="equation"><DD><IMG WIDTH="242" HEIGHT="97"
 SRC="images/nlpeq109.gif"
 ALT="g_i = {\partial f \over \partial x_i}
 = {f(x + h_ie_i) - f(x) \over h_i}"></DL>
<LI> Second-order derivatives based on function calls only
      (Dennis and Schnabel 1983, p. 80, 104): for dense
      Hessian, <SPAN CLASS="mathfont"><I>n</I>+<I>n<SUP>2</SUP></I>/2</SPAN> additional function calls are needed:

<DL CLASS="equation"><DD><IMG WIDTH="508" HEIGHT="101"
 SRC="images/nlpeq110.gif"
 ALT="{\partial^2 f \over \partial x_i \partial x_j} =
 {f(x+h_ie_i+h_je_j) - f(x+h_ie_i) - f(x+h_je_j) + f(x)
 \over h_i h_j}"></DL>
<LI> Second-order derivatives based on gradient calls
      (Dennis and Schnabel, 1983, p. 103):
      <SPAN CLASS="mathfont"><I>n</I></SPAN> additional gradient calls are needed:

<DL CLASS="equation"><DD><IMG WIDTH="421" HEIGHT="101"
 SRC="images/nlpeq111.gif"
 ALT="{\partial^2 f \over \partial x_i \partial x_j} =
 {g_i(x + h_je_j) - g_i(x) \over 2h_j} + {g_j(x + h_ie_i) - g_j(x) \over 2h_i}"></DL></UL>
<P><H4><I>Central Difference Approximations</I></H4>
<P><UL>
<LI> First-order derivatives: <SPAN CLASS="mathfont">2<I>n</I></SPAN> additional function
      calls are needed:

<DL CLASS="equation"><DD><IMG WIDTH="294" HEIGHT="97"
 SRC="images/nlpeq112.gif"
 ALT="g_i = {\partial f \over \partial x_i}
 = {f(x + h_ie_i) - f(x - h_ie_i) \over 2h_i}"></DL>
<LI> Second-order derivatives based on function calls only
      (Abramowitz and Stegun 1972, p. 884): for dense Hessian,
      <SPAN CLASS="mathfont">2<I>n</I>+4<I>n<SUP>2</SUP></I>/2</SPAN> additional function calls are needed:
<P><DL CLASS="equation"><DD><IMG WIDTH="747" HEIGHT="167"
 SRC="images/nlpeq113.gif"
 ALT="{\partial^2 f \over \partial x^2_i} & = &
 {-f(x + 2h_ie_i) + 16f(x + h_ie_i) - ...
 ...- f(x+h_ie_i-h_je_j)
 - f(x-h_ie_i+h_je_j) + f(x-h_ie_i-h_je_j)
 \over 4h_ih_j} "></DL>
<LI> Second-order derivatives based on gradient:
      <SPAN CLASS="mathfont">2<I>n</I></SPAN> additional gradient calls are needed:

<DL CLASS="equation"><DD><IMG WIDTH="530" HEIGHT="101"
 SRC="images/nlpeq114.gif"
 ALT="{\partial^2 f \over \partial x_i \partial x_j} =
 {g_i(x + h_je_j) - g_i(x - h_je_j) \over 4h_j} +
 {g_j(x + h_ie_i) - g_j(x - h_ie_i) \over 4h_i}"></DL></UL>
<P>The FDIGITS=<A NAME="idxnlp0460">&#13;</A>and CDIGITS=
<A NAME="idxnlp0461">&#13;</A>options can be used for specifying
the number of accurate digits in the evaluation of objective
function and nonlinear constraints. These specifications
are helpful in determining an appropriate interval size <SPAN CLASS="mathfont"><I>h</I></SPAN> to be
used in the finite-difference formulas.
<P>The FDINT= option<A NAME="idxnlp0462">&#13;</A>specifies whether the
finite difference intervals <SPAN CLASS="mathfont"><I>h</I></SPAN> should be computed using
an algorithm of Gill, Murray, Saunders, and Wright (1983)
or based only on the information of the FDIGITS= and
CDIGITS= options. For FDINT=OBJ, the interval <SPAN CLASS="mathfont"><I>h</I></SPAN> is
based on the behavior of the objective function; for
FDINT=CON, the interval <SPAN CLASS="mathfont"><I>h</I></SPAN> is based on the behavior of
the nonlinear constraints functions; and for FDINT=ALL,
the interval <SPAN CLASS="mathfont"><I>h</I></SPAN> is based on both, the behavior of the
objective function and the nonlinear constraints functions.
Note that the algorithm of Gill, Murray, Saunders, and Wright
(1983) to compute the finite difference intervals <SPAN CLASS="mathfont"><I>h</I><SUB><I>j</I></SUB></SPAN> can
be very expensive in the number of function calls. If the FDINT=
option is specified, it is currently performed twice, the first
time before the optimization process starts and the second
time after the optimization terminates.
<P>If FDINT= is not specified, the step sizes <SPAN CLASS="mathfont"><I>h</I><SUB><I>j</I></SUB></SPAN>, <SPAN CLASS="mathfont"><I>j</I> = 1, ... ,<I>n</I></SPAN>,
are defined as follows:
<UL>
<LI> for the forward-difference approximation of first-order
      derivatives using function calls and second-order
      derivatives using gradient calls:
      <IMG WIDTH="156" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="images/nlpeq115.gif"
 ALT="h_j = \sqrt[2]{\eta_j} (1. + | x_j|)">,<LI> for the forward-difference approximation of second-order
      derivatives that use only function calls and all
      central-difference formulas:
      <IMG WIDTH="156" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="images/nlpeq116.gif"
 ALT="h_j = \sqrt[3]{\eta_j} (1. + | x_j|)">.</UL>
where <IMG WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/nlpeq117.gif"
 ALT="\eta"> is defined using the FDIGITS= option:
<UL>
<LI> If the number of accurate digits is specified with
      FDIGITS=<SPAN CLASS="mathfont"><I>r</I></SPAN>, <IMG WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/nlpeq117.gif"
 ALT="\eta"> is set to <SPAN CLASS="mathfont">10<SUP>-<I>r</I></SUP></SPAN>.
<LI> If FDIGITS= is not specified, <IMG WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/nlpeq117.gif"
 ALT="\eta"> is set to the
      machine precision <IMG WIDTH="11" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/nlpeq24.gif"
 ALT="\epsilon">.</UL>
<P>For FDINT=OBJ and FDINT=ALL, the FDIGITS= specification
is used in computing the forward and central finite-difference
intervals.
<P>If the problem has nonlinear constraints
and the FD[=] option is specified,
the first-order formulas are used to compute finite difference
approximations of the Jacobian matrix <SPAN CLASS="mathfont"><I>JC</I>(<I>x</I>)</SPAN>.
You can use the CDIGITS=
option to specify the number of accurate digits in the constraint
evaluations to define the step sizes <SPAN CLASS="mathfont"><I>h</I><SUB><I>j</I></SUB></SPAN>, <SPAN CLASS="mathfont"><I>j</I> = 1, ... ,<I>n</I></SPAN>.
For FDINT=CON and FDINT=ALL, the CDIGITS= specification is used
in computing the forward and central finite-difference intervals.
<P><B>Note:</B> If you are not able to specify
analytic derivatives and the finite-difference approximations
provided by PROC NLP are not good enough to solve your
problem, you may program better finite-difference
approximations using the GRADIENT, JACOBIAN, CRPJAC, or HESSIAN
statement and the program statements.
<P>
<!--Navigation Panel-->
<TABLE BORDER="0" CELLPADDING="0">
<TR VALIGN="TOP">
  <TD ALIGN="CENTER">
  <A HREF="index.htm">
  <IMG BORDER="0" SRC="../../common/images/cont1.gif" ALT="Chapter Contents" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Chapter Contents</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect27.htm"><IMG BORDER="0" SRC="../../common/images/prev1.gif" ALT="Previous" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Previous</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect29.htm"><IMG BORDER="0" SRC="../../common/images/next1.gif" ALT="Next" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Next</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="#topofpage">
  <IMG BORDER="0" SRC="../../common/images/top1.gif" ALT="Top" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Top</FONT></A></TD>
</TR>
</TABLE>
<P><!--End of Navigation Panel-->
<P><FONT SIZE="1"><A HREF="../../common/images/copyrite.htm">Copyright &copy; 1999 by SAS Institute Inc., Cary, NC, USA. All rights reserved.</A></FONT>
</BODY>
</HTML>
