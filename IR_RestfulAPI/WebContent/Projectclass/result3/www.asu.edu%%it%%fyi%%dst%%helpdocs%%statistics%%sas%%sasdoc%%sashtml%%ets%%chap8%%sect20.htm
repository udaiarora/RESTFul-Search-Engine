<HTML>
<HEAD>
<TITLE>Autoregressive Error Model</TITLE>
<LINK REL="STYLESHEET" TYPE="text/css" HREF="../sas.css">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<!--Navigation Panel-->
<TABLE BORDER="0" CELLPADDING="0">
<TR VALIGN="TOP">
  <TD ALIGN="CENTER">
  <A NAME="topofpage" HREF="index.htm">
  <IMG BORDER="0" SRC="../../common/images/cont1.gif" ALT="Chapter Contents" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Chapter Contents</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect19.htm"><IMG BORDER="0" SRC="../../common/images/prev1.gif" ALT="Previous" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Previous</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect21.htm"><IMG BORDER="0" SRC="../../common/images/next1.gif" ALT="Next" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Next</FONT></A></TD>
</TR>
</TABLE>
<TABLE BGCOLOR="#CCCC99" WIDTH="100%" CELLPADDING=4>
<TR>
  <TD VALIGN=MIDDLE CLASS="chaphead"><I><FONT SIZE="2">The AUTOREG Procedure</FONT></I></TD>
</TR>
</TABLE><BR>
<P><!--End of Navigation Panel-->
<H2>Autoregressive Error Model  </H2>
<P>The regression model with autocorrelated disturbances is as follows:
<P>
<DL CLASS="equation"><DD><IMG WIDTH="103" HEIGHT="75"
 SRC="images/auteq64.gif"
 ALT="y_{t} = x_{t}' {\beta}+{\nu}_{t}"></DL>

<DL CLASS="equation"><DD><IMG WIDTH="253" HEIGHT="70"
 SRC="images/auteq20.gif"
 ALT="{\nu}_{t} = {\epsilon}_{t} -
 {\varphi}_{1} {\nu}_{t-1}
-{ ... }- {\varphi}_{m} {\nu}_{t-m}"></DL>

<DL CLASS="equation"><DD><IMG WIDTH="79" HEIGHT="76"
 SRC="images/auteq65.gif"
 ALT="{\epsilon}_{t}  \rm{N}(0,{\sigma}^2)"></DL>
<P>In these equations,
<SPAN CLASS="mathfont"><I>y</I><SUB><I>t</I></SUB></SPAN> are the dependent values,
<SPAN CLASS="mathfont"><b>x</b><sub><I>t</I></sub></SPAN> is a column vector of regressor variables,
<IMG WIDTH="15" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq6.gif"
 ALT="{{\beta}}"> is a column vector of structural parameters,
and <IMG WIDTH="17" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq4.gif"
 ALT="{{\epsilon}_{t}}"> is normally and independently
distributed with a mean of 0 and a variance of <IMG WIDTH="14" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq58.gif"
 ALT="{{\sigma}}"><SPAN CLASS="mathfont"><SUP>2</SUP></SPAN>.
Note that in this parameterization, the signs of the autoregressive
parameters are reversed from the parameterization documented in most
of the literature.
<P>PROC AUTOREG offers four estimation methods for the
autoregressive error model.
<A NAME="idxaut0217">&#13;</A><A NAME="idxaut0216">&#13;</A>The default method, Yule-Walker (YW) estimation,
is the fastest computationally.
The Yule-Walker method used by PROC AUTOREG is described
in Gallant and Goebel (1976).
Harvey (1981) calls this method the <I>two-step full transform method</I>.
The other methods are iterated YW, unconditional least squares (ULS),
and maximum likelihood (ML).
The ULS method is also referred to as nonlinear least squares (NLS) or exact
least squares (ELS).
<P>You can use all of the methods with data containing missing values,
but you should use ML estimation if the missing values are plentiful.
See the section &#34;Alternative Autocorrelation Correction Methods&#34; later in
this chapter for further discussion of the advantages of different methods.
<P><H3><I>The Yule-Walker Method</I></H3>
<A NAME="idxaut0219">&#13;</A><A NAME="idxaut0218">&#13;</A>Let <B><IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"></B> represent the vector of autoregressive parameters
<P>
<DL CLASS="equation"><DD><IMG WIDTH="163" HEIGHT="75"
 SRC="images/auteq67.gif"
 ALT="{{\varphi}}=({\varphi}_{1},{\varphi}_{2}, { ... },
 {\varphi}_{m})'"></DL>
<P>and let the variance matrix of the error vector
<IMG WIDTH="133" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq68.gif"
 ALT="{{\nu}=( {\nu}_{1},{ ... }, {\nu}_{N})'}">
be <B><IMG WIDTH="17" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq69.gif"
 ALT="{\Sigma}"></B>
<P>
<DL CLASS="equation"><DD><IMG WIDTH="150" HEIGHT="76"
 SRC="images/auteq70.gif"
 ALT="E( {\nu}{{\nu}'} ) = {{\Sigma}} = {\sigma}^2{V}"></DL>
<P>If the vector of autoregressive parameters <B><IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"></B> is known,
the matrix <B>V</B> can be computed from the autoregressive parameters.
<B><IMG WIDTH="17" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq69.gif"
 ALT="{\Sigma}"></B> is then <IMG WIDTH="38" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq71.gif"
 ALT="{{\sigma}^2{V}}">.
Given <B><IMG WIDTH="17" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq69.gif"
 ALT="{\Sigma}"></B>, the efficient estimates of regression parameters <B><IMG WIDTH="15" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq6.gif"
 ALT="{{\beta}}"></B>
can be computed using generalized least squares (GLS).
The GLS estimates then yield the unbiased estimate of the variance
<IMG WIDTH="14" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq58.gif"
 ALT="{{\sigma}}"><SPAN CLASS="mathfont"><SUP>2</SUP></SPAN>,
<P>The Yule-Walker method alternates estimation of <B><IMG WIDTH="15" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq6.gif"
 ALT="{{\beta}}"></B> using
generalized least squares with estimation of <B><IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"></B> using the
Yule-Walker equations applied to the sample autocorrelation function.
The YW method starts by forming the OLS estimate of <B><IMG WIDTH="15" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq6.gif"
 ALT="{{\beta}}"></B>.
Next, <B><IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"></B> is estimated from the sample autocorrelation function
of the OLS residuals using the Yule-Walker equations.
Then <B>V</B> is estimated from the estimate of <B><IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"></B>,
and <B><IMG WIDTH="17" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq69.gif"
 ALT="{\Sigma}"></B> is estimated from <B>V</B> and the OLS estimate
of <IMG WIDTH="22" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq5.gif"
 ALT="{{\sigma}^2}">.
The autocorrelation corrected estimates of the regression parameters
<B><IMG WIDTH="15" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq6.gif"
 ALT="{{\beta}}"></B> are then computed by GLS using the estimated <B><IMG WIDTH="17" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq69.gif"
 ALT="{\Sigma}"></B> matrix.
These are the Yule-Walker estimates.
<P>If the ITER option is specified,
the Yule-Walker residuals are used to form a new sample autocorrelation
function, the new autocorrelation function is used to form a new estimate
of <B><IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"></B> and <B>V</B>, and the GLS estimates are recomputed using
the new variance matrix.
This alternation of estimates continues until either the maximum change
in the <IMG WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq72.gif"
 ALT="\hat{\varphi}"> estimate between iterations is
less than the value specified by the CONVERGE= option or the maximum number
of allowed iterations is reached.
This produces the Iterated Yule-Walker estimates.
Iteration of the estimates may not yield much improvement.
<P>The  Yule-Walker equations,
<A NAME="idxaut0221">&#13;</A><A NAME="idxaut0220">&#13;</A>solved to obtain <IMG WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq72.gif"
 ALT="\hat{\varphi}"> and a preliminary estimate of <IMG WIDTH="22" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq5.gif"
 ALT="{{\sigma}^2}">,
are
<P>
<DL CLASS="equation"><DD><IMG WIDTH="74" HEIGHT="72"
 SRC="images/auteq73.gif"
 ALT="{R\hat{{\varphi}}}=-r"></DL>
<P>Here <SPAN CLASS="mathfont"><b>r</b> = (<I>r<SUb>1</SUb></I>,  ...  , <I>r</I><sub><I>m</I></sub>)'</SPAN>,
where <SPAN CLASS="mathfont"><I>r</I><SUB><I>i</I></SUB></SPAN> is the lag <I>i</I> sample autocorrelation.
The matrix <B>R</B> is the Toeplitz matrix
<A NAME="idxaut0223">&#13;</A><A NAME="idxaut0222">&#13;</A>whose <I>i,j</I>th element is <SPAN CLASS="mathfont"> <I>r</I><SUB>|<I>i</I>-<I>j</I>|</SUB></SPAN>.
If you specify a subset model, then
only the rows and columns of <B>R</B> and <B>r</B> corresponding to the
subset of lags specified are used.
<P>If the BACKSTEP option is specified,
for purposes of significance testing, the matrix
<SPAN CLASS="mathfont">[<b>R</b> &#160; <b>r</b>]</SPAN> is treated
as a sum-of-squares-and-crossproducts matrix
arising from a simple regression with <SPAN CLASS="mathfont"><I>N</I>-<I>k</I></SPAN> observations,
where <I>k</I> is the number of estimated parameters.
<P><H3><I>The Unconditional Least Squares and Maximum Likelihood Methods</I></H3>
Define the transformed error, <SPAN CLASS="mathfont"><b>e</b></SPAN>, as
<P>
<DL CLASS="equation"><DD>
<SPAN CLASS="mathfont"><b>e</b> = <b>L</b><sup>-1</sup><b>n</b></SPAN>
</DL>
where <IMG WIDTH="100" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq74.gif"
 ALT="{n = y - X{\beta}}">.<P>The unconditional sum of squares for the model, S, is
<P>
<DL CLASS="equation"><DD>
<SPAN CLASS="mathfont"><I>S</I> = <b>n</b>' <b>V</b><sup>-1</sup><b>n</b> = <b>e</b>'<b>e</b></SPAN>
</DL>
The ULS estimates are computed by minimizing <SPAN CLASS="mathfont"><I>S</I></SPAN>
with respect to the parameters <IMG WIDTH="15" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq6.gif"
 ALT="{{\beta}}"> and <IMG WIDTH="21" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq7.gif"
 ALT="{{\varphi}_{i}}">.<P>The full log likelihood function for the autoregressive error model is
<P>
<DL CLASS="equation"><DD><IMG WIDTH="349" HEIGHT="93"
 SRC="images/auteq75.gif"
 ALT="l =
- \frac{N}2{\ln}(2 {\pi})
- \frac{N}2{\ln}({\sigma}^2)-
\frac{1}2{\ln}({|{V}|})-\frac{S}{2{\sigma}^2}"></DL>
<P>where <IMG WIDTH="30" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq76.gif"
 ALT="{{|{V}|}}"> denotes determinant of <SPAN CLASS="mathfont"><b>V</b></SPAN>.
For the ML method, the likelihood function is maximized by minimizing
an equivalent sum-of-squares function.
<P>Maximizing <I>l</I> with respect to <IMG WIDTH="22" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq5.gif"
 ALT="{{\sigma}^2}"> (and concentrating
<IMG WIDTH="22" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq5.gif"
 ALT="{{\sigma}^2}"> out of the likelihood) and dropping the constant term
<IMG WIDTH="183" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq77.gif"
 ALT="{-\frac{N}2{\ssbeleven {\ln}(2 {\pi})+1-{\ln}(N)}}">
produces the concentrated log likelihood function
<P>
<DL CLASS="equation"><DD><IMG WIDTH="164" HEIGHT="93"
 SRC="images/auteq78.gif"
 ALT="l_{c} = -\frac{N}2{\ln}(S{|{V}|}^{1/N})"></DL>
<P>Rewriting the variable term within the logarithm gives
<P>
<DL CLASS="equation"><DD><IMG WIDTH="172" HEIGHT="79"
 SRC="images/auteq79.gif"
 ALT="S_{ml} =
{|{L}|}^{1/N}e'e{|{L}|}^{1/N}"></DL>
<P>PROC AUTOREG computes the ML estimates by minimizing the objective function
<IMG WIDTH="179" HEIGHT="42" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq80.gif"
 ALT="{S_{ml} ={|{L}|}^{1/N}e'e{|{L}|}^{1/N}}">.<P>The maximum likelihood estimates may not exist for some data sets
(Anderson and Mentz 1980).
This is the case for very regular data sets, such as an exact linear trend.
<P><H3><I>Computational Methods</I></H3>
<H4><I>Sample Autocorrelation Function</I></H4>
The sample autocorrelation function is computed from the structural residuals
or noise <SPAN CLASS="mathfont"><b>n<sub>t</sub></b> = <I>y</I><sub><I>t</I></sub>-<b>x</b><sub><I>t</I></sub>'<b>b</b></SPAN>,
where <B>b</B> is the current estimate of <B><IMG WIDTH="15" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq6.gif"
 ALT="{{\beta}}"></B>.
The sample autocorrelation function is the sum of all available
lagged products of <SPAN CLASS="mathfont"><b>n</b><sub><I>t</I></sub></SPAN> of order <I>j</I> divided by
<SPAN CLASS="mathfont"><I>l</I>+<I>j</I></SPAN>, where <SPAN CLASS="mathfont"><I>l</I></SPAN> is the number of such products.
<P>If there are no missing values, then <SPAN CLASS="mathfont"><I>l</I>+<I>j</I> = <I>N</I></SPAN>,
the number of observations.
In this case, the Toeplitz matrix of autocorrelations, <B>R</B>,
is at least positive semidefinite.
If there are missing values,
these autocorrelation estimates of <I>r</I> can yield an <B>R</B> matrix
that is not positive semidefinite.
If such estimates occur, a warning message is printed,
and the estimates are tapered by exponentially declining
weights until <B>R</B> is positive definite.
<P><H4><I>Data Transformation and the Kalman Filter</I></H4>
The calculation of <B>V</B> from <B><IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"></B> for the general AR(<I>m</I>) model
is complicated, and the size of <B>V</B> depends on the number of observations.
Instead of actually calculating <B>V</B> and performing GLS in the usual way,
in practice a Kalman filter algorithm is used to transform the data
and compute the GLS results through a recursive process.
<P><A NAME="idxaut0225">&#13;</A><A NAME="idxaut0224">&#13;</A>In all of the estimation methods, the original data are transformed by
the inverse of the Cholesky root of <B>V</B>.
Let <B>L</B> denote the Cholesky root of <B>V</B>,
that is <SPAN CLASS="mathfont"><b>V</b> = <b>LL'</b></SPAN> with <B>L</B> lower triangular.
For an AR(<I>m</I>) model,  <SPAN CLASS="mathfont"><b>L</b><sup>-1</sup></SPAN> is a band diagonal matrix with
<I>m</I> anomalous rows at the beginning and the
autoregressive parameters along the remaining rows.
Thus, if there are no missing values, after the first <I>m</I>-1 observations
the data are transformed as
<P>
<DL CLASS="equation"><DD><IMG WIDTH="259" HEIGHT="72"
 SRC="images/auteq81.gif"
 ALT="z_{t}= x_{t}+ \hat{{\varphi}}_{1} x_{t-1}
+{ ... }+ \hat{{\varphi}}_{m} x_{t-m}"></DL>
<P>The transformation is carried out using a Kalman filter,
<A NAME="idxaut0227">&#13;</A><A NAME="idxaut0226">&#13;</A>and the lower triangular matrix <B>L</B> is never directly computed.
The Kalman filter algorithm, as it applies here,
is described in Harvey and Phillips (1979) and Jones (1980).
Although <B>L</B> is not computed explicitly,
for ease of presentation the remaining discussion is in terms of <B>L</B>.
If there are missing values, then the submatrix of
<B>L</B> consisting of the rows and columns with nonmissing values
is used to generate the transformations.
<P><H4><I>Gauss-Newton Algorithms</I></H4>
The ULS and ML estimates employ a Gauss-Newton algorithm
<A NAME="idxaut0229">&#13;</A><A NAME="idxaut0228">&#13;</A>to minimize the sum of squares and maximize the log likelihood, respectively.
The relevant optimization is performed simultaneously for
both the regression and AR parameters.
The OLS estimates of <IMG WIDTH="15" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq6.gif"
 ALT="{{\beta}}"> and the Yule-Walker estimates of <B><IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"></B>
are used as starting values for these methods.
<P>The Gauss-Newton algorithm requires the derivatives
of <B>e</B> or <IMG WIDTH="62" HEIGHT="42" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq82.gif"
 ALT="{{|{L}|}^{1/N}e}"> with
respect to the parameters.
The derivatives with respect to the parameter vector <B><IMG WIDTH="15" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq6.gif"
 ALT="{{\beta}}"></B> are
<P>
<DL CLASS="equation"><DD><IMG WIDTH="112" HEIGHT="97"
 SRC="images/auteq83.gif"
 ALT="\frac{{\partial}e}{{\partial}{{\beta}}'} =
- L^{-1}X"></DL>

<DL CLASS="equation"><DD><IMG WIDTH="205" HEIGHT="102"
 SRC="images/auteq84.gif"
 ALT="\frac{{\partial}{|{L}|}^{1/N}e}{
{\partial}{{\beta}}'} =
- {|{L}|}^{1/N} L^{-1}X"></DL>
<P>These derivatives are computed by the transformation described previously.
The derivatives with respect to <B><IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"></B> are computed by differentiating
the Kalman filter recurrences and the equations for the initial conditions.
<P><H3><I>Variance Estimates and Standard Errors</I></H3>
For the Yule-Walker method,
the estimate of the error variance, <SPAN CLASS="mathfont"><I>s<SUP>2</SUP></I></SPAN>, is the error sum of
squares from the last application of GLS,
divided by the error degrees of freedom
(number of observations <I>N</I> minus the number of free parameters).
<P>The variance-covariance matrix for the components of <B>b</B> is taken as
<SPAN CLASS="mathfont"><I>s<SUp>2</SUp></I>(<b>X</b>' <b>V</b><sup>-1</sup> <b>X</b>)<sup>-1</sup></SPAN>
for the Yule-Walker method.
For the ULS and ML methods,
the variance-covariance matrix of the parameter estimates is computed
as <SPAN CLASS="mathfont"><I>s<SUp>2</SUp></I> (<b>J'J</b>)<sup>-1</sup></SPAN>.
For the ULS method, <B>J</B> is the matrix of derivatives of <B>e</B>
with respect to the parameters.
For the ML method, <B>J</B> is the matrix of derivatives
of <IMG WIDTH="62" HEIGHT="42" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq82.gif"
 ALT="{{|{L}|}^{1/N}e}">
divided by <IMG WIDTH="53" HEIGHT="42" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq85.gif"
 ALT="{{|{L}|}^{1/N}}">.
The estimate of the variance-covariance matrix of <B>b</B>
assuming that <B><IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"></B> is known is
<SPAN CLASS="mathfont"><I>s<SUp>2</SUp></I> (<b>X</b>' <b>V</b><sup>-1</sup><b>X</b>)<sup>-1</sup></SPAN>.
<P>Park and Mitchell (1980) investigated the small sample
performance of the standard error estimates obtained from some of
these methods.
In particular, simulating an AR(1) model for the
noise term, they found that the standard errors calculated using
GLS with an estimated autoregressive parameter underestimated the
true standard errors. These estimates of standard errors are the
ones calculated by PROC AUTOREG with the Yule-Walker method.
<P>The estimates of the
standard errors calculated with the ULS or ML methods take into account
the joint estimation of the AR and the regression parameters and may
give more accurate standard-error values than the YW method.
At the same values of the autoregressive parameters,
the ULS and ML standard errors will always be larger than those computed
from Yule-Walker.
However, simulations of the models used by Park and Mitchell suggest that
the ULS and ML standard error estimates can also be underestimates.
Caution is advised, especially when the estimated autocorrelation is high
and the sample size is small.
<P>High autocorrelation in the residuals is a symptom of lack of fit.
An autoregressive error model should not be used as a nostrum for models that
simply do not fit.
It is often the case that time series variables tend to move as a random walk.
This means that an AR(1) process with a parameter near one absorbs
a great deal of the variation.
See <A HREF="sect34.htm">Example 8.3</A> later in this chapter,
which fits a linear trend to a sine wave.
<P>For ULS or ML estimation,
the joint variance-covariance matrix of all the regression and
autoregression parameters is computed.
For the Yule-Walker method, the variance-covariance matrix is computed
only for the regression parameters.
<P><H3><I>Lagged Dependent Variables</I></H3>
The Yule-Walker estimation method is not directly appropriate for
estimating models that include lagged dependent variables
among the regressors.
Therefore, the maximum likelihood method is the default when
the LAGDEP or LAGDEP= option is specified in the MODEL statement.
However, when lagged dependent variables are used,
the maximum likelihood estimator is not exact maximum likelihood
but is conditional on the first few values of the dependent variable.
<P>
<!--Navigation Panel-->
<TABLE BORDER="0" CELLPADDING="0">
<TR VALIGN="TOP">
  <TD ALIGN="CENTER">
  <A HREF="index.htm">
  <IMG BORDER="0" SRC="../../common/images/cont1.gif" ALT="Chapter Contents" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Chapter Contents</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect19.htm"><IMG BORDER="0" SRC="../../common/images/prev1.gif" ALT="Previous" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Previous</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect21.htm"><IMG BORDER="0" SRC="../../common/images/next1.gif" ALT="Next" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Next</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="#topofpage">
  <IMG BORDER="0" SRC="../../common/images/top1.gif" ALT="Top" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Top</FONT></A></TD>
</TR>
</TABLE>
<P><!--End of Navigation Panel-->
<P><FONT SIZE="1"><A HREF="../../common/images/copyrite.htm">Copyright &copy; 1999 by SAS Institute Inc., Cary, NC, USA. All rights reserved.</A></FONT>
</BODY>
</HTML>
