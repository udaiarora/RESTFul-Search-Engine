<HTML>
<HEAD>
<TITLE>Generalized Durbin-Watson Tests</TITLE>
<LINK REL="STYLESHEET" TYPE="text/css" HREF="../sas.css">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<!--Navigation Panel-->
<TABLE BORDER="0" CELLPADDING="0">
<TR VALIGN="TOP">
  <TD ALIGN="CENTER">
  <A NAME="topofpage" HREF="index.htm">
  <IMG BORDER="0" SRC="../../common/images/cont1.gif" ALT="Chapter Contents" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Chapter Contents</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect23.htm"><IMG BORDER="0" SRC="../../common/images/prev1.gif" ALT="Previous" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Previous</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect25.htm"><IMG BORDER="0" SRC="../../common/images/next1.gif" ALT="Next" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Next</FONT></A></TD>
</TR>
</TABLE>
<TABLE BGCOLOR="#CCCC99" WIDTH="100%" CELLPADDING=4>
<TR>
  <TD VALIGN=MIDDLE CLASS="chaphead"><I><FONT SIZE="2">The AUTOREG Procedure</FONT></I></TD>
</TR>
</TABLE><BR>
<P><!--End of Navigation Panel-->
<H2>Generalized Durbin-Watson Tests  </H2>
<P>Consider the following linear regression model:
<P>
<DL CLASS="equation"><DD><IMG WIDTH="99" HEIGHT="72"
 SRC="images/auteq164.gif"
 ALT="Y={X{\beta}}+{{\nu}}"></DL>
<P>where <B>X</B> is an <SPAN CLASS="mathfont"><I>N</I>*<I>k</I></SPAN> data matrix, <B><IMG WIDTH="15" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq6.gif"
 ALT="{{\beta}}"></B> is a
<SPAN CLASS="mathfont"><I>k</I>*1</SPAN> coefficient vector, and <B><IMG WIDTH="14" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq145.gif"
 ALT="{{\nu}}"></B> is a <SPAN CLASS="mathfont"><I>N</I>*1</SPAN>
disturbance vector.
The error term <B><IMG WIDTH="14" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq145.gif"
 ALT="{{\nu}}"></B> is assumed to be generated by the <I>j</I>th
order autoregressive process
<IMG WIDTH="14" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq145.gif"
 ALT="{{\nu}}"><SPAN CLASS="mathfont"><SUB><I>t</I></SUB></SPAN>=<IMG WIDTH="11" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq165.gif"
 ALT="{\epsilon}"><SPAN CLASS="mathfont"><SUB><I>t</I></SUB></SPAN>-<IMG WIDTH="15" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq66.gif"
 ALT="{\varphi}"><SPAN CLASS="mathfont"><SUB><I>j</I></SUB></SPAN><IMG WIDTH="14" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq145.gif"
 ALT="{{\nu}}"><SPAN CLASS="mathfont"><SUB><I>t</I>-<I>j</I></SUB></SPAN> where
<IMG WIDTH="66" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq166.gif"
 ALT="{{| {\varphi}_{j}|} \lt 1}">, <IMG WIDTH="17" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq4.gif"
 ALT="{{\epsilon}_{t}}">
is a sequence of independent normal error terms with mean 0 and
variance <IMG WIDTH="14" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq58.gif"
 ALT="{{\sigma}}"><SPAN CLASS="mathfont"><SUP>2</SUP></SPAN>. Usually,
the Durbin-Watson statistic is used to test the null hypothesis
<IMG WIDTH="95" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq167.gif"
 ALT="{H_{0}: {\varphi}_{1}=0}"> against
<IMG WIDTH="109" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq168.gif"
 ALT="{H_{1}: - {\varphi}_{1}\gt}">.
Vinod (1973) generalized the Durbin-Watson statistic:
<P>
<DL CLASS="equation"><DD><IMG WIDTH="198" HEIGHT="109"
 SRC="images/auteq169.gif"
 ALT="d_{j}=\frac{\sum_{t=j+1}^N{(\hat{{\nu}}_{t}-\hat{{\nu}}_{t-j})^2
}}{\sum_{t=1}^N{\hat{{\nu}}_{t}^2} } "></DL>
<P>where <IMG WIDTH="14" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq170.gif"
 ALT="\hat{\nu}"> are OLS residuals.
Using the matrix notation,
<P>
<DL CLASS="equation"><DD><IMG WIDTH="153" HEIGHT="97"
 SRC="images/auteq171.gif"
 ALT="d_{j}=\frac{{{\nu}}'M{A}_{j}'
A_{j}M{{\nu}}} {{{\nu}}'M{{\nu}}}"></DL>
<P>where <SPAN CLASS="mathfont"><b>M</b> = <b>I</b><sub><I>N</I></sub>-<b>X(X'X)<sup>-1</sup>X'</b></SPAN> and
<SPAN CLASS="mathfont"><b>A</b><sub><I>j</I></sub></SPAN> is a <SPAN CLASS="mathfont">(<I>N</I>-<I>j</I>) &times;<I>N</I></SPAN> matrix:
<P>
<DL CLASS="equation"><DD><IMG WIDTH="360" HEIGHT="147"
 SRC="images/auteq172.gif"
 ALT="A_{j} =
[ \matrix{ -1 & 0 & { ... } & 0 & 1 & 0 & { ... } & 0 \cr
0 & -1 & 0 &...
 ...ots} &
{\vdots} & {\vdots} \cr
0 & { ... } & 0 & -1 & 0 & { ... } & 0 & 1}
]"></DL>
<P>and there are <SPAN CLASS="mathfont"><I>j</I>-1</SPAN> zeros
between -1 and 1 in each row of matrix <B>A</B><SPAN CLASS="mathfont"><SUB><I>j</I></SUB></SPAN>.
<P>The QR factorization of the design matrix <B>X</B> yields a <SPAN CLASS="mathfont"><I>N</I>*<I>N</I></SPAN>
orthogonal matrix <B>Q</B>
<P>
<DL CLASS="equation"><DD>
<SPAN CLASS="mathfont"><b>X</b> = <b>QR</b></SPAN>
</DL>
<P>where R is a <SPAN CLASS="mathfont"><I>N</I>*<I>k</I></SPAN> upper triangular matrix.
There exists a <SPAN CLASS="mathfont"><I>N</I>*(<I>N</I>-<I>k</I>)</SPAN> submatrix of <B>Q</B> such that
<SPAN CLASS="mathfont"><b>Q</b><sub>1</sub><b>Q</b><sub>1</sub>' = <b>M</b></SPAN> and
<SPAN CLASS="mathfont"><b>Q</b><sub>1</sub>'<b>Q</b><sub>1</sub> = <b>I</b><sub><I>N</I>-<I>k</I></sub></SPAN>.
Consequently, the generalized Durbin-Watson statistic is stated
as a ratio of two quadratic forms:
<P>
<DL CLASS="equation"><DD><IMG WIDTH="131" HEIGHT="103"
 SRC="images/auteq173.gif"
 ALT="d_{j}=\frac{\sum_{l=1}^n{{\lambda}_{jl} {\xi}_{l}}^2}{\sum_{l=1}^n{{\xi}_{l}^2}}"></DL>
<P>where <IMG WIDTH="76" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq174.gif"
 ALT="{{\lambda}_{j1}{ ... }{\lambda}_{jn}}"> are upper
<I>n</I> eigenvalues of
<SPAN CLASS="mathfont"><b>MA</b><sub><I>j</I></sub>'<b>A</b><sub><I>j</I></sub><b>M</b></SPAN> and
<IMG WIDTH="17" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq175.gif"
 ALT="{ {\xi}_{l}}"> is a standard normal variate, and
<SPAN CLASS="mathfont"><I>n</I> = min(<I>N</I>-<I>k</I>, <I>N</I>-<I>j</I>)</SPAN>.
These eigenvalues are obtained by a singular value decomposition of
<SPAN CLASS="mathfont"><b>Q</b><sub>1</sub>'<b>A</b><sub><I>j</I></sub>'</SPAN>
(Golub and Loan 1989; Savin and White 1978).
<P>The marginal probability (or <I>p</I>-value) for <SPAN CLASS="mathfont"><I>d</I><SUB><I>j</I></SUB></SPAN> given
<SPAN CLASS="mathfont"><I>c<SUB>0</SUB></I></SPAN> is
<P>
<DL CLASS="equation"><DD><IMG WIDTH="301" HEIGHT="102"
 SRC="images/auteq176.gif"
 ALT="\rm{Prob}(\frac{\sum_{l=1}^n{{\lambda}_{jl}
 {\xi}_{l}^2}}{\sum_{l=1}^n{{\xi}_{l}^2}} \lt
c_{0})=\rm{Prob}(q_{j} \lt 0)"></DL>
<P>where

<DL CLASS="equation"><DD><IMG WIDTH="156" HEIGHT="110"
 SRC="images/auteq177.gif"
 ALT="q_{j}=\sum_{l=1}^n{( {\lambda}_{jl}-c_{0}) {\xi}_{l}^2}"></DL>
<P>When the null
hypothesis <IMG WIDTH="94" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq178.gif"
 ALT="{H_{0}: {\varphi}_{j}=0}"> holds,
the quadratic form <SPAN CLASS="mathfont"><I>q</I><SUB><I>j</I></SUB></SPAN> has the characteristic function
<P>
<DL CLASS="equation"><DD><IMG WIDTH="257" HEIGHT="110"
 SRC="images/auteq179.gif"
 ALT="{\phi}_{j}(t)={\prod_{l=1}^n
 (1-2( {\lambda}_{jl}-c_{0})it)^{-1/2}}"></DL>
<P>The distribution function is uniquely determined by this
characteristic function:
<P>
<DL CLASS="equation"><DD><IMG WIDTH="359" HEIGHT="100"
 SRC="images/auteq180.gif"
 ALT="F(x) = \frac{1}2 + \frac{1}{2{\pi}}\int_{0}^{{\infty}}{\frac{e^{itx}{\phi}_{j}(-t)- e^{-itx}{\phi}_{j}(t)}{it}dt}"></DL>
<P>For example, to test <IMG WIDTH="95" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq181.gif"
 ALT="{H_{0}: {\varphi}_{4}=0}">
given <IMG WIDTH="145" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq182.gif"
 ALT="{{\varphi}_{1}={\varphi}_{2}={\varphi}_{3}=0}">
against <IMG WIDTH="109" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq183.gif"
 ALT="{H_{1}: - {\varphi}_{4}\gt}">, the marginal probability
(<I>p</I>-value) can be used:
<P>
<DL CLASS="equation"><DD><IMG WIDTH="308" HEIGHT="98"
 SRC="images/auteq184.gif"
 ALT="F(0) = \frac{1}2 +
\frac{1}{2{\pi}}\int_{0}^{{\infty}}{\frac{\ssbeleven
({\phi}_{4}(-t)-{\phi}_{4}(t))} {it}dt}"></DL>
<P>where
<P>
<DL CLASS="equation"><DD><IMG WIDTH="260" HEIGHT="110"
 SRC="images/auteq185.gif"
 ALT="{\phi}_{4}(t) = {\prod_{l=1}^n
(1-2({\lambda}_{4{l}}-\hat{d}_{4})it )^{-1/2}}"></DL>
<P>and <IMG WIDTH="21" HEIGHT="40" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq186.gif"
 ALT="{ \hat{d}_{4}}"> is the calculated value of the
fourth-order Durbin-Watson statistic.
<P>In the Durbin-Watson test,
the marginal probability indicates positive autocorrelation
(<IMG WIDTH="70" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq187.gif"
 ALT="{-{\varphi}_{j}\gt}">) if it is
less than the level of significance (<IMG WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq188.gif"
 ALT="{\alpha}">), while you can conclude
that a negative autocorrelation (<IMG WIDTH="70" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq189.gif"
 ALT="{-{\varphi}_{j}\lt}">) exists
if the marginal probability based on the computed Durbin-Watson statistic
is greater than 1-<IMG WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq188.gif"
 ALT="{\alpha}">. Wallis (1972) presented
tables for bounds tests of fourth-order autocorrelation and
Vinod (1973) has given tables for a five percent significance level for
orders two to four. Using the AUTOREG procedure, you can calculate
the exact <I>p</I>-values for the general order of Durbin-Watson
test statistics. Tests for the absence of autocorrelation of order
<I>p</I> can be performed sequentially; at the <I>j</I>th step, test
<IMG WIDTH="94" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq178.gif"
 ALT="{H_{0}: {\varphi}_{j}=0}">
given <IMG WIDTH="163" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq190.gif"
 ALT="{ {\varphi}_{1}={ ... } = {\varphi}_{j-1}=0}">
against <IMG WIDTH="46" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq191.gif"
 ALT="{ {\varphi}_{j}{\neq}0}">.
However, the size of the sequential test is not known.
<P>The Durbin-Watson statistic is computed from the OLS residuals,
while that of the autoregressive error model uses residuals that are the
difference between the predicted values and the actual values.
When you use the Durbin-Watson test from the residuals of the autoregressive
error model,
you must be aware that this test is only an approximation. See &#34;Regression
with Autoregressive Errors&#34; earlier in this chapter.
If there are missing values, the Durbin-Watson statistic is computed
using all the nonmissing values and ignoring the gaps caused by
missing residuals. This does not affect the significance level
of the resulting test, although the power of the test against
certain alternatives may be adversely affected. Savin and
White (1978) have examined
the use of the Durbin-Watson statistic with missing values.
<P><H3><I>Tests for Serial Correlation with Lagged Dependent Variables</I></H3>
When regressors contain lagged dependent variables, the
Durbin-Watson statistic (<SPAN CLASS="mathfont"><I>d<SUB>1</SUB></I></SPAN>) for the first-order
autocorrelation is biased toward 2 and has reduced power.
Wallis (1972) shows that the bias in the Durbin-Watson statistic
(<SPAN CLASS="mathfont"><I>d<SUB>4</SUB></I></SPAN>) for the fourth-order autocorrelation is smaller
than the bias in <SPAN CLASS="mathfont"><I>d<SUB>1</SUB></I></SPAN> in the presence of a first-order
lagged dependent variable.
Durbin (1970) proposed two alternative statistics
(Durbin <I>h</I> and <I>t</I>) that are asymptotically equivalent.
The <I>h</I> statistic is written as
<P>
<DL CLASS="equation"><DD><IMG WIDTH="162" HEIGHT="89"
 SRC="images/auteq192.gif"
 ALT="h = \hat{{\rho}}\sqrt{N / (1-N\hat{V})}"></DL>
<P>where <IMG WIDTH="207" HEIGHT="41" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq193.gif"
 ALT="{\hat{{\rho}}=\sum_{t=2}^N{\hat{{\nu}}_{t}\hat{{\nu}}_{t-1}}/\sum_{t=1}^N{\hat{{\nu}}_{t}^2}}"> 
and  <IMG WIDTH="18" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="images/auteq194.gif"
 ALT="\hat{V}"> is the least-squares
variance estimate for the coefficient of the lagged dependent variable.
Durbin's <I>t</I>-test consists of regressing the OLS residuals
<IMG WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq195.gif"
 ALT="{\hat{{\nu}}_{t}}"> on explanatory variables and
<IMG WIDTH="36" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq196.gif"
 ALT="{\hat{{\nu}}_{t-1}}"> and testing the significance of the estimate for
coefficient of <IMG WIDTH="36" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="images/auteq196.gif"
 ALT="{\hat{{\nu}}_{t-1}}">.<P>Inder (1984) shows that the Durbin-Watson test for the absence of
first-order autocorrelation is generally more powerful than the <I>h</I>-test
in finite samples.
Refer to Inder (1986) and King and Wu (1991) for
the Durbin-Watson test in the presence of lagged dependent variables.
<P>
<!--Navigation Panel-->
<TABLE BORDER="0" CELLPADDING="0">
<TR VALIGN="TOP">
  <TD ALIGN="CENTER">
  <A HREF="index.htm">
  <IMG BORDER="0" SRC="../../common/images/cont1.gif" ALT="Chapter Contents" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Chapter Contents</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect23.htm"><IMG BORDER="0" SRC="../../common/images/prev1.gif" ALT="Previous" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Previous</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="sect25.htm"><IMG BORDER="0" SRC="../../common/images/next1.gif" ALT="Next" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Next</FONT></A></TD>
  <TD ALIGN=CENTER>
  <A HREF="#topofpage">
  <IMG BORDER="0" SRC="../../common/images/top1.gif" ALT="Top" WIDTH="99" HEIGHT="16"><BR><FONT SIZE="-2">Top</FONT></A></TD>
</TR>
</TABLE>
<P><!--End of Navigation Panel-->
<P><FONT SIZE="1"><A HREF="../../common/images/copyrite.htm">Copyright &copy; 1999 by SAS Institute Inc., Cary, NC, USA. All rights reserved.</A></FONT>
</BODY>
</HTML>
